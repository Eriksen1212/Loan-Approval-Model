# -*- coding: utf-8 -*-
"""Loan Approval Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jwJ1piK_dIGTjxh51FO8E9Fi0-7QzFo4
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("accepted_2007_to_2018Q4.csv", low_memory=False)
df.shape

"""**변수(컬럼) 살펴보기**"""

df.info()
df.head()

"""결측치(Missing values) 확인

결측치가 많다면 적절히 처리(drop, 평균 대체, 0 대체, 모드 대체 등) 방법 고민
"""

df.isnull().sum().sort_values(ascending=False)

"""일정 이상 결측치가 발생하면 그 column을 drop하고 남은 columns 확인"""

df = df.dropna(thresh=100000, axis=1)

df.isnull().sum().sort_values(ascending=False)

"""결측치가 존재하는 행 제거"""

df = df.dropna()

"""결측치 존재하는 행 제거 결과 211567개의 행 존재"""

df.isnull().sum().sort_values(ascending=False)
df.shape

df.tail()

df.describe()

"""target 변수로 사용할 loan_status의 고유값들 확인

값별 개수 확인 (value_counts())

샘플 데이터 확인
"""

print(df['loan_status'].unique())  # 고유 값 출력
print(df['loan_status'].value_counts())  # 값별 개수 출력
df['loan_status'].head(10)  # 상위 10개 출력

"""**타겟 변수를 정의**

Lending Club 예시에서는 loan_status 컬럼이 “Fully Paid(정상 상환)”, “Charged Off(연체/부실)” 등을 나타내므로, 이 값을 이진 분류용 타겟으로 사용 가능.

“Charged Off”이면 연체(1), “Fully Paid”이면 정상(0) 등으로 변환하려고 했는데 더 많은 case가 있어서 fully paid와 changed off만 두고 할지, 아니면 세 가지 케이스를 나눌지 고민 필요
"""

# 1) 'Fully Paid' 또는 'Charged Off'만 남기고 나머지 행은 제외
df = df[(df['loan_status'] == "Fully Paid") | (df['loan_status'] == "Charged Off")].copy()

# 2) 새 컬럼 'target'을 생성: Charged Off -> 1, Fully Paid -> 0
df['target'] = df['loan_status'].apply(lambda x: 1 if x == "Charged Off" else 0)

# 확인
print(df['loan_status'].value_counts())
print(df['target'].value_counts())

"""대출 금액(loan_amnt), 이자율(int_rate), 신용등급(grade), 연소득(annual_inc) 등의 분포를 대략적으로 파악."""

# 타겟 분포 확인
sns.countplot(x='target', data=df)
plt.title("Loan Status Distribution")
plt.show()

# 숫자형 변수의 분포
sns.histplot(df['loan_amnt'], bins=50, kde=True)
plt.title("Loan Amount Distribution")
plt.show()

"""# **데이터 전처리 및 특징 공학(Feature Engineering)**

**컬럼 선택 및 변환**

분석에 의미 있는 컬럼만 추출

예: 대출금액, 금리, 신용등급, 직업, 연소득, 부채비율, 대출기간, 연체기록 등.
필요 없는 컬럼(e.g. ID, URL, 문제 해결과 무관한 날짜 등)은 제거.

결측이 많았던 employment_length는 drop 되었을 수도 있으므로 컬럼이 없으면 자동으로 빼고 복사를 진행
"""

# 원래 선택하려고 했던 컬럼 리스트
selected_columns = [
    'loan_amnt', 'int_rate', 'grade', 'annual_inc', 'employment_length',
    'home_ownership', 'purpose', 'dti', 'delinq_2yrs', 'target'
]

# 실제 df에 존재하는 컬럼만 걸러내기
existing_columns = [col for col in selected_columns if col in df.columns]

# 데이터프레임에서 해당 컬럼들만 복사
df_selected = df[existing_columns].copy()

# 확인용 출력
print("최종 선택된 컬럼:", existing_columns)
print("df_selected.shape:", df_selected.shape)

"""**범주형 변수 인코딩**

‘grade’(A, B, C 등), ‘home_ownership’(OWN, RENT, MORTGAGE 등), ‘purpose’(‘credit_card’, ‘debt_consolidation’ 등) 등은 **범주형(Categorical)**이므로 원-핫 인코딩(One-Hot Encoding) 또는 라벨 인코딩(Label Encoding)을 적용.
"""

df_encoded = pd.get_dummies(df_selected, columns=['grade','home_ownership','purpose'])

"""**Scaling**

연소득(annual_inc)처럼 값의 범위가 매우 큰 변수는 로그 변환 혹은 MinMaxScaler/StandardScaler 등을 적용할 수 있음.
"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_encoded['loan_amnt_scaled'] = scaler.fit_transform(df_encoded[['loan_amnt']])

"""# 모델링 (Machine Learning)

**라이브러리 임포트**
"""

# 기본 파이썬 라이브러리
import pandas as pd
import numpy as np

# 머신러닝 관련
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score,
                             roc_auc_score,
                             confusion_matrix,
                             classification_report)

# 옵션: 경고 무시(불필요한 워닝 억제)
import warnings
warnings.filterwarnings('ignore')

"""**데이터 분리 (Train/Test Split)**

X: 모델의 입력(feature) 데이터로, target 열(종속 변수)을 제외한 모든 데이터를 포함

drop('target', axis=1): target 열을 제거하여 독립 변수 데이터만 남김

y: 모델의 출력(label) 데이터로, target 열을 사용

전체 데이터의 20%를 테스트 데이터로 사용하고, 나머지 80%는 훈련 데이터로 사용

stratify=y로 타겟 비율에 맞게 샘플링.
"""

from sklearn.model_selection import train_test_split, GridSearchCV

X = df_encoded.drop('target', axis=1)
y = df_encoded['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

"""**로지스틱 회귀(Logistic Regression) 모델**

max_iter=1000 : 데이터 규모가 큰 경우, 기본값(100)으로는 수렴 경고가 뜰 수 있으므로 늘려줍니다.

predict_proba() : (N, 2) 형태 확률을 반환 → 두 번째 열([:,1])이 클래스 1의 예측 확률.
"""

model_lr = LogisticRegression(max_iter=1000)  # 기본 max_iter=100으로는 경고 발생 가능성
model_lr.fit(X_train, y_train)

# 예측
y_pred_lr = model_lr.predict(X_test)
y_pred_proba_lr = model_lr.predict_proba(X_test)[:, 1]  # 클래스 1일 확률

# 성능 평가
acc_lr = accuracy_score(y_test, y_pred_lr)
roc_lr = roc_auc_score(y_test, y_pred_proba_lr)
cm_lr = confusion_matrix(y_test, y_pred_lr)

print("=== Logistic Regression 결과 ===")
print("Accuracy:", acc_lr)
print("ROC-AUC:", roc_lr)
print("Confusion Matrix:\n", cm_lr)
print("Classification Report:\n", classification_report(y_test, y_pred_lr))

"""**Decision Tree 모델**

max_depth=5 : 트리 깊이를 제한해 과적합 방지(하이퍼파라미터).

실제 적용 시에는 max_depth, min_samples_split 등 여러 파라미터를 조정해볼 수 있습니다.

**파라미터 후보 설정**

max_depth: 트리의 최대 깊이(깊어질수록 복잡, 과적합 가능성↑)

min_samples_split: 내부 노드를 분할하기 위한 최소 샘플 수

min_samples_leaf: 리프 노드가 되기 위한 최소 샘플 수

criterion: 분할 시 불순도 측정 방법('gini' 또는 'entropy')
"""

param_grid_dt = {
    'max_depth': [3, 5, 7, 10, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4, 8],
    'criterion': ['gini', 'entropy']  # 불순도 측정 기준
}

"""GridSearchCV 설정"""

dt = DecisionTreeClassifier(random_state=42)
grid_dt = GridSearchCV(
    estimator=dt,
    param_grid=param_grid_dt,
    scoring='roc_auc',  # ROC-AUC 기반으로 최적 파라미터 찾기
    cv=5,               # 5-Fold 교차검증
    n_jobs=-1           # CPU 병렬처리(최대한 활용)
)

grid_dt.fit(X_train, y_train)

print("\n=== GridSearchCV: Decision Tree ===")
print("Best Params:", grid_dt.best_params_)
print("Best CV Score (ROC-AUC):", grid_dt.best_score_)

"""최적 모델로 평가

여기서 **grid_dt.best_params_**를 보면 어떤 하이퍼파라미터 조합이 최적이었는지 알 수 있습니다.

cv=5로 교차검증해 과적합 방지도 어느 정도 해주며, 다양한 파라미터를 시도해봄으로써 성능 상승을 기대할 수 있습니다.
"""

best_dt = grid_dt.best_estimator_

# 테스트 세트 예측
y_pred_dt = best_dt.predict(X_test)
y_pred_proba_dt = best_dt.predict_proba(X_test)[:, 1]

acc_dt = accuracy_score(y_test, y_pred_dt)
roc_dt = roc_auc_score(y_test, y_pred_proba_dt)
cm_dt = confusion_matrix(y_test, y_pred_dt)

print("\n=== 최적 Decision Tree 모델 성능 ===")
print(f"Accuracy: {acc_dt:.4f}")
print(f"ROC-AUC : {roc_dt:.4f}")
print("Confusion Matrix:\n", cm_dt)
print("Classification Report:\n", classification_report(y_test, y_pred_dt))

"""RandomForest 모델

n_estimators=100 : 결정 트리를 100개 생성.

더 높은 성능을 위해 max_depth, min_samples_split, bootstrap 등 다양한 파라미터를 시도할 수 있습니다.

파라미터 후보 설정

n_estimators: 앙상블에 사용할 트리(의사결정나무) 개수

max_depth: 각 트리의 최대 깊이(너무 깊으면 과적합, 너무 얕으면 과소적합)

min_samples_split: 노드 분할을 위한 최소 샘플 수

min_samples_leaf: 리프가 되기 위한 최소 샘플 수

max_features: 각 노드에서 분할에 사용할 피처 수('auto'=전부, 'sqrt'=루트 개수, 'log2'=log2 개수)
"""

param_grid_rf = {
    'n_estimators': [100, 200, 300],    # 트리 개수
    'max_depth': [5, 10, 15, None],
    'max_features': ['auto', 'sqrt', 'log2'],  # 분할 시 고려할 피처 수
}

"""GridSearchCV 설정"""

rf = RandomForestClassifier(random_state=42)

grid_rf = GridSearchCV(
    estimator=rf,
    param_grid=param_grid_rf,
    scoring='roc_auc',
    cv=5,
    n_jobs=-1
)

grid_rf.fit(X_train, y_train)

print("\n=== GridSearchCV: Random Forest ===")
print("Best Params:", grid_rf.best_params_)
print("Best CV Score (ROC-AUC):", grid_rf.best_score_)

"""최적 모델로 평가"""

best_rf = grid_rf.best_estimator_

y_pred_rf = best_rf.predict(X_test)
y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]

acc_rf = accuracy_score(y_test, y_pred_rf)
roc_rf = roc_auc_score(y_test, y_pred_proba_rf)
cm_rf = confusion_matrix(y_test, y_pred_rf)

print("\n=== 최적 Random Forest 모델 성능 ===")
print(f"Accuracy: {acc_rf:.4f}")
print(f"ROC-AUC : {roc_rf:.4f}")
print("Confusion Matrix:\n", cm_rf)
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

"""**XGBoost 사용**

n_estimators : 트리 개수

learning_rate : 학습률(작게 설정할수록 일반화 성능이 좋아질 수 있으나 더 오래 걸림)

max_depth : 트리 깊이 제한
"""

import xgboost as xgb

model_xgb = xgb.XGBClassifier(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=42,
    use_label_encoder=False,       # 버전에 따라 경고 메시지 방지
    eval_metric='logloss'          # 기존 default: 'auc' 등이 가능
)

model_xgb.fit(X_train, y_train)

y_pred_xgb = model_xgb.predict(X_test)
y_pred_proba_xgb = model_xgb.predict_proba(X_test)[:, 1]

acc_xgb = accuracy_score(y_test, y_pred_xgb)
roc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)

print("\n=== XGBoost 결과 ===")
print("Accuracy:", acc_xgb)
print("ROC-AUC:", roc_xgb)
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("Classification Report:\n", classification_report(y_test, y_pred_xgb))

"""**모델 성능 비교**

위에서 얻은 Accuracy, ROC-AUC 점수를 한 번에 비교해보면 어떤 모델이 좋은지 대략적으로 알 수 있습니다.
"""

print("\n=== 성능 비교 ===")
print(f"Logistic Regression: Acc={acc_lr:.4f}, ROC-AUC={roc_lr:.4f}")
print(f"Decision Tree      : Acc={acc_dt:.4f}, ROC-AUC={roc_dt:.4f}")
print(f"Random Forest      : Acc={acc_rf:.4f}, ROC-AUC={roc_rf:.4f}")
print(f"XGBoost            : Acc={acc_xgb:.4f}, ROC-AUC={roc_xgb:.4f}")

"""연체(부도) 위험을 최대한 놓치지 않고 찾아내야 하는 금융권 리스크 모델”이라면, ROC-AUC, Recall 등 민감도가 더 중요한 경우가 많아 Random Forest가 낫다고 판단"""

# 1) 예측 (label)
y_pred_rf = best_rf.predict(X_test)

# 2) 예측 확률 (class=1)
y_pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]

# 3) 평가 지표 계산
acc_rf = accuracy_score(y_test, y_pred_rf)
roc_rf = roc_auc_score(y_test, y_pred_proba_rf)
cm_rf = confusion_matrix(y_test, y_pred_rf)

print("=== 최종 모델: Random Forest 테스트 세트 결과 ===")
print(f"Accuracy : {acc_rf:.4f}")
print(f"ROC-AUC  : {roc_rf:.4f}")
print("Confusion Matrix:\n", cm_rf)
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

"""Accuracy(정확도): 0.7822 (78.22%)

ROC-AUC: 0.6944

Confusion Matrix:

TN = 7154

FP = 184

FN = 1874

TP = 236
TN=7154

Precision(양성 정밀도): 0.56 (Class=1 기준)

Recall(양성 재현율): 0.11 (Class=1 기준)

F1-score(양성): 0.19
"""